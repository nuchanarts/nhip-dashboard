import streamlit as st
import pandas as pd
import plotly.express as px
import requests
import json
from urllib.parse import quote

# =============================
# App Setup
# =============================
st.set_page_config(page_title="NHIP Executive Dashboard", layout="wide")
st.title("ðŸ¥ NHIP Executive Dashboard")

SPREADSHEET_ID = "1Y4FANer87OduQcK7XctCjJ0FBEKTHlXJ4aMZklcqzFU"

# =============================
# Load Sheet Names
# =============================
@st.cache_data(ttl=300)
def get_sheet_names():
    try:
        url = f"https://docs.google.com/spreadsheets/d/{SPREADSHEET_ID}/gviz/tq?tqx=out:json"
        res = requests.get(url)
        text = res.text
        json_str = text[text.find("{"):text.rfind("}")+1]
        data = json.loads(json_str)
        sheets = data.get("sheets", [])
        return [s["properties"]["title"] for s in sheets]
    except Exception as e:
        return []

sheet_list = get_sheet_names()

if not sheet_list:
    st.error("âŒ à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¸­à¹ˆà¸²à¸™à¸£à¸²à¸¢à¸Šà¸·à¹ˆà¸­ sheet à¹„à¸”à¹‰")
    st.stop()

# =============================
# Load All Sheets Data
# =============================
@st.cache_data(ttl=300)
def load_all_sheets():
    sheet_names = get_sheet_names()
    all_dataframes = []
    for sheet in sheet_names:
        try:
            encoded = quote(sheet)
            url = f"https://docs.google.com/spreadsheets/d/{SPREADSHEET_ID}/gviz/tq?tqx=out:csv&sheet={encoded}"
            temp_df = pd.read_csv(url)
            if temp_df.shape[0] > 0:
                temp_df.columns = temp_df.columns.str.strip()
                temp_df["Sheet"] = sheet
                all_dataframes.append(temp_df)
        except Exception as e:
            continue
    if not all_dataframes:
        return None
    return pd.concat(all_dataframes, ignore_index=True)

df = load_all_sheets()
if df is None:
    st.error("âŒ à¹„à¸¡à¹ˆà¸žà¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸ sheet à¹ƒà¸” à¹†")
    st.stop()

# =============================
# Detect Columns
# =============================
zone_col    = next((c for c in df.columns if "à¹€à¸‚à¸•"      in c), None)
province_col= next((c for c in df.columns if "à¸ˆà¸±à¸‡à¸«à¸§à¸±à¸”"  in c), None)
date_col    = next((c for c in df.columns if "à¸§à¸±à¸™" in c or "date" in c.lower()), None)

if date_col:
    df[date_col] = pd.to_datetime(df[date_col], errors="coerce")

# =============================
# Sidebar Filters
# =============================
st.sidebar.header("ðŸ”Ž à¸•à¸±à¸§à¸à¸£à¸­à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥")

filtered_df = df.copy()

# Filter by Zone
if zone_col:
    zones = sorted(df[zone_col].dropna().unique())
    selected_zones = st.sidebar.multiselect("à¹€à¸¥à¸·à¸­à¸à¹€à¸‚à¸•", zones, default=zones)
    filtered_df = filtered_df[filtered_df[zone_col].isin(selected_zones)]

# Filter by Province
if province_col:
    provinces = sorted(filtered_df[province_col].dropna().unique())
    selected_provinces = st.sidebar.multiselect("à¹€à¸¥à¸·à¸­à¸à¸ˆà¸±à¸‡à¸«à¸§à¸±à¸”", provinces, default=provinces)
    filtered_df = filtered_df[filtered_df[province_col].isin(selected_provinces)]

# =============================
# Executive Summary
# =============================
st.header("ðŸ“Š Executive Summary")

col1, col2, col3 = st.columns(3)

col1.metric("à¸ˆà¸³à¸™à¸§à¸™à¸£à¸²à¸¢à¸à¸²à¸£à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”", len(filtered_df))
if province_col:
    col2.metric("à¸ˆà¸³à¸™à¸§à¸™à¸ˆà¸±à¸‡à¸«à¸§à¸±à¸”à¸—à¸µà¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥", filtered_df[province_col].nunique())
col3.metric("à¸ˆà¸³à¸™à¸§à¸™ Sheet à¸—à¸µà¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥", filtered_df["Sheet"].nunique())

st.divider()

# =============================
# Trend Analysis
# =============================
if date_col:
    st.subheader("ðŸ§  à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¹à¸™à¸§à¹‚à¸™à¹‰à¸¡à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´")

    trend_df = (
        filtered_df
        .groupby(["Sheet", filtered_df[date_col].dt.date])
        .size()
        .reset_index(name="à¸ˆà¸³à¸™à¸§à¸™")
    )

    for sheet in trend_df["Sheet"].unique():
        sheet_data = trend_df[trend_df["Sheet"] == sheet].sort_values(date_col)
        if len(sheet_data) >= 2:
            last  = sheet_data["à¸ˆà¸³à¸™à¸§à¸™"].iloc[-1]
            prev  = sheet_data["à¸ˆà¸³à¸™à¸§à¸™"].iloc[-2]
            diff  = last - prev
            pct   = (diff / prev * 100) if prev != 0 else 0

            status = "ðŸŸ¡ à¸„à¸‡à¸—à¸µà¹ˆ"
            if diff > 0:
                status = "ðŸŸ¢ à¹€à¸žà¸´à¹ˆà¸¡à¸‚à¸¶à¹‰à¸™"
            elif diff < 0:
                status = "ðŸ”´ à¸¥à¸”à¸¥à¸‡"

            st.markdown(f"â€¢ **{sheet}** : {status} {diff:+} ({pct:.1f}%)")

    fig_trend = px.line(
        trend_df,
        x=date_col,
        y="à¸ˆà¸³à¸™à¸§à¸™",
        color="Sheet",
        markers=True,
        color_discrete_sequence=px.colors.sequential.Teal
    )
    st.plotly_chart(fig_trend, use_container_width=True)

st.divider()

# =============================
# Full Table
# =============================
st.subheader("ðŸ“‹ à¸•à¸²à¸£à¸²à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¸à¸£à¸­à¸‡à¹à¸¥à¹‰à¸§")
st.dataframe(filtered_df, use_container_width=True)

st.download_button(
    label="ðŸ“¥ à¸”à¸²à¸§à¸™à¹Œà¹‚à¸«à¸¥à¸” CSV",
    data=filtered_df.to_csv(index=False).encode("utf-8"),
    file_name="NHIP_filtered_data.csv",
    mime="text/csv"
)
