import streamlit as st
import pandas as pd
import plotly.express as px
import requests
import json
from urllib.parse import quote

# ==============================
# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÅ‡∏≠‡∏õ
# ==============================
st.set_page_config(page_title="NHIP Executive Dashboard", layout="wide")

st.markdown("""
<style>
.main { background-color: #F3FBF8; }
h1, h2, h3 { color: #127C5C; }
div[data-testid="metric-container"] {
    background: white;
    padding: 15px;
    border-radius: 12px;
    border-left: 6px solid #1FBF8F;
}
</style>
""", unsafe_allow_html=True)

st.title("üè• NHIP Executive Dashboard")

SPREADSHEET_ID = "1Y4FANer87OduQcK7XctCjJ0FBEKTHlXJ4aMZklcqzFU"

# ==============================
# ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠ Sheet ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
# ==============================
@st.cache_data(ttl=300)
def get_sheet_names():
    url = f"https://docs.google.com/spreadsheets/d/{SPREADSHEET_ID}/gviz/tq?tqx=out:json"
    res = requests.get(url)
    text = res.text
    json_str = text[text.find("{"):text.rfind("}")+1]
    data = json.loads(json_str)
    sheets = data.get("sheets", [])
    return [s["properties"]["title"] for s in sheets]

# ==============================
# ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏∏‡∏Å Sheet
# ==============================
@st.cache_data(ttl=300)
def load_all_sheets():
    sheet_list = get_sheet_names()
    all_dfs = []

    for sheet in sheet_list:
        try:
            encoded_sheet = quote(sheet)
            url = f"https://docs.google.com/spreadsheets/d/{SPREADSHEET_ID}/gviz/tq?tqx=out:csv&sheet={encoded_sheet}"
            df = pd.read_csv(url)
            df.columns = df.columns.str.strip()
            df["Sheet"] = sheet
            all_dfs.append(df)
        except:
            pass

    return pd.concat(all_dfs, ignore_index=True)

df = load_all_sheets()

# ==============================
# ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
# ==============================
zone_col = next((c for c in df.columns if "‡πÄ‡∏Ç‡∏ï" in c), None)
province_col = next((c for c in df.columns if "‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î" in c), None)
date_col = next((c for c in df.columns if "‡∏ß‡∏±‡∏ô" in c or "date" in c.lower()), None)

if date_col:
    df[date_col] = pd.to_datetime(df[date_col], errors="coerce")

# ==============================
# Sidebar Filters
# ==============================
st.sidebar.header("üìä ‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")

filtered_df = df.copy()

# Filter ‡πÄ‡∏Ç‡∏ï
if zone_col:
    zone_list = sorted(df[zone_col].dropna().unique())
    selected_zone = st.sidebar.multiselect(
        "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏Ç‡∏ï",
        zone_list,
        default=zone_list
    )
    filtered_df = filtered_df[filtered_df[zone_col].isin(selected_zone)]

# Filter ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î
if province_col:
    province_list = sorted(filtered_df[province_col].dropna().unique())
    selected_province = st.sidebar.multiselect(
        "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î",
        province_list,
        default=province_list
    )
    filtered_df = filtered_df[filtered_df[province_col].isin(selected_province)]

# ==============================
# Executive Summary
# ==============================
st.header("üìä Executive Summary")

col1, col2, col3 = st.columns(3)

col1.metric("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", len(filtered_df))

if province_col:
    col2.metric("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î", filtered_df[province_col].nunique())

col3.metric("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Sheet ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", filtered_df["Sheet"].nunique())

st.divider()

# ==============================
# ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
# ==============================
if date_col:

    trend_df = (
        filtered_df
        .groupby(["Sheet", filtered_df[date_col].dt.date])
        .size()
        .reset_index(name="‡∏à‡∏≥‡∏ô‡∏ß‡∏ô")
    )

    st.subheader("üß† ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î")

    for sheet in trend_df["Sheet"].unique():
        sheet_data = trend_df[trend_df["Sheet"] == sheet].sort_values(date_col)

        if len(sheet_data) >= 2:
            last = sheet_data["‡∏à‡∏≥‡∏ô‡∏ß‡∏ô"].iloc[-1]
            prev = sheet_data["‡∏à‡∏≥‡∏ô‡∏ß‡∏ô"].iloc[-2]

            change = last - prev
            percent = (change / prev * 100) if prev != 0 else 0

            if change > 0:
                status = "üü¢ ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô"
            elif change < 0:
                status = "üî¥ ‡∏•‡∏î‡∏•‡∏á"
            else:
                status = "üü° ‡∏Ñ‡∏á‡∏ó‡∏µ‡πà"

            st.markdown(f"**{sheet}** : {status} {change:+} ({percent:.1f}%)")

    fig_trend = px.line(
        trend_df,
        x=date_col,
        y="‡∏à‡∏≥‡∏ô‡∏ß‡∏ô",
        color="Sheet",
        markers=True,
        color_discrete_sequence=px.colors.sequential.Teal
    )

    st.plotly_chart(fig_trend, use_container_width=True)

st.divider()

# ==============================
# ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
# ==============================
st.dataframe(filtered_df, use_container_width=True)

st.download_button(
    "üì• ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (CSV)",
    filtered_df.to_csv(index=False).encode("utf-8"),
    file_name="NHIP_filtered_data.csv",
    mime="text/csv"
)
